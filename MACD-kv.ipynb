{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary Libraries\n",
    "import yfinance as yf, pandas as pd, shutil, os, time, glob\n",
    "import numpy as np\n",
    "import requests\n",
    "from get_all_tickers import get_tickers as gt\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of stocks chosen to observe: 60\n"
     ]
    }
   ],
   "source": [
    "# If you have a list of your own you would like to use just create a new list instead of using this, for example: tickers = [\"FB\", \"AMZN\", ...] \n",
    "tickers = gt.get_tickers_filtered(mktcap_min=150000, mktcap_max=4000000)\n",
    "# Check that the amount of tickers isn't more than 2000\n",
    "print(\"The amount of stocks chosen to observe: \" + str(len(tickers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These two lines remove the Stocks folder and then recreate it in order to remove old stocks. Make sure you have created a Stocks Folder the first time you run this.\n",
    "shutil.rmtree(\"SMA_Analysis/Stocks/\")\n",
    "os.mkdir(\"SMA_Analysis/Stocks/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration = 0\n",
      "Iteration = 1\n",
      "Iteration = 2\n",
      "Iteration = 3\n",
      "Iteration = 4\n",
      "Iteration = 5\n",
      "Iteration = 6\n",
      "Iteration = 7\n",
      "Iteration = 8\n",
      "Iteration = 9\n",
      "Iteration = 10\n",
      "Iteration = 11\n",
      "Iteration = 12\n",
      "Iteration = 13\n",
      "Iteration = 14\n",
      "Iteration = 15\n",
      "Iteration = 16\n",
      "Iteration = 17\n",
      "Iteration = 18\n",
      "Iteration = 19\n",
      "The amount of stocks we successfully imported: 20\n"
     ]
    }
   ],
   "source": [
    "# Holds the amount of API calls we executed\n",
    "Amount_of_API_Calls = 0\n",
    "# This while loop is reponsible for storing the historical data for each ticker in our list. Note that yahoo finance sometimes incurs json.decode errors and because of this we are sleeping for 2\n",
    "# seconds after each iteration, also if a call fails we are going to try to execute it again.\n",
    "# Also, do not make more than 2,000 calls per hour or 48,000 calls per day or Yahoo Finance may block your IP. The clause \"(Amount_of_API_Calls < 1800)\" below will stop the loop from making\n",
    "# too many calls to the yfinance API.\n",
    "# Prepare for this loop to take some time. It is pausing for 2 seconds after importing each stock.\n",
    "\n",
    "# Used to make sure we don't waste too many API calls on one Stock ticker that could be having issues\n",
    "Stock_Failure = 0\n",
    "Stocks_Not_Imported = 0\n",
    "\n",
    "# Used to iterate through our list of tickers\n",
    "i=0\n",
    "while (i < len(tickers)) and (Amount_of_API_Calls < 20):\n",
    "    try:\n",
    "        print(\"Iteration = \" + str(i))\n",
    "        stock = tickers[i]  # Gets the current stock ticker\n",
    "        temp = yf.Ticker(str(stock))\n",
    "        Hist_data = temp.history(period=\"5y\")  # Tells yfinance what kind of data we want about this stock (In this example, all of the historical data)\n",
    "        Hist_data.to_csv(\"SMA_Analysis/Stocks/\"+stock+\".csv\")  # Saves the historical data in csv format for further processing later\n",
    "        time.sleep(2)  # Pauses the loop for two seconds so we don't cause issues with Yahoo Finance's backend operations\n",
    "        Amount_of_API_Calls += 1 \n",
    "        Stock_Failure = 0\n",
    "        i += 1  # Iteration to the next ticker\n",
    "    except ValueError:\n",
    "        print(\"Yahoo Finance Backend Error, Attempting to Fix\")  # An error occured on Yahoo Finance's backend. We will attempt to retreive the data again\n",
    "        if Stock_Failure > 5:  # Move on to the next ticker if the current ticker fails more than 5 times\n",
    "            i+=1\n",
    "            Stocks_Not_Imported += 1\n",
    "        Amount_of_API_Calls += 1\n",
    "        Stock_Failure += 1\n",
    "    # Handle SSL error\n",
    "    except requests.exceptions.SSLError as e:\n",
    "        print(\"Yahoo Finance Backend Error, Attempting to Fix SSL\")  # An error occured on Yahoo Finance's backend. We will attempt to retreive the data again\n",
    "        if Stock_Failure > 5:  # Move on to the next ticker if the current ticker fails more than 5 times\n",
    "            i+=1\n",
    "            Stocks_Not_Imported += 1\n",
    "        Amount_of_API_Calls += 1\n",
    "        Stock_Failure += 1\n",
    "print(\"The amount of stocks we successfully imported: \" + str(i - Stocks_Not_Imported))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the path for each stock file in a list\n",
    "list_files = (glob.glob(\"SMA_Analysis/Stocks/*.csv\"))\n",
    "# You can use this line to limit the analysis to a portion of the stocks in the \"stocks folder\"\n",
    "# list_files = list_files[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataframe that we will be adding the final analysis of each stock to\n",
    "Compare_Stocks = pd.DataFrame(columns=[\"Company\", \"Days_Observed\", \"Crosses\", \"True_Positive\", \"False_Positive\", \"True_Negative\", \"False_Negative\", \"Sensitivity\", \n",
    "\"Specificity\", \"Accuracy\", \"TPR\", \"FPR\"])\n",
    "# While loop to cycle through the stock paths\n",
    "count = 0\n",
    "for stock in list_files:\n",
    "    # Dataframe to hold the historical data of the stock we are interested in.\n",
    "    Hist_data = pd.read_csv(stock)\n",
    "    Company = ((os.path.basename(stock)).split(\".csv\")[0])  # Name of the company\n",
    "    # Constants for the stock that we will be updating later\n",
    "    Days_Observed = 0\n",
    "    Crosses = 0\n",
    "    True_Positive = 0\n",
    "    False_Positive = 0\n",
    "    True_Negative = 0\n",
    "    False_Negative = 0\n",
    "    Sensitivity = 0\n",
    "    Specificity = 0\n",
    "    Accuracy = 0\n",
    "    # This list holds the closing prices of a stock\n",
    "    prices = []\n",
    "    c = 0\n",
    "     # Add the closing prices to the prices list and make sure we start at greater than 2 dollars to reduce outlier calculations.\n",
    "    while c < len(Hist_data):\n",
    "        if Hist_data.iloc[c,4] > float(2.00):  # Check that the closing price for this day is greater than $2.00\n",
    "            prices.append(Hist_data.iloc[c,4])\n",
    "        c += 1\n",
    "    prices_df = pd.DataFrame(prices)  # Make a dataframe from the prices list\n",
    "    # Calculate exponentiall weighted moving averages:\n",
    "    day12 = prices_df.ewm(span=12).mean()  #\n",
    "    day26 = prices_df.ewm(span=26).mean()\n",
    "    macd = []  # List to hold the MACD line values\n",
    "    counter=0  # Loop to substantiate the MACD line\n",
    "    while counter < (len(day12)):\n",
    "        macd.append(day12.iloc[counter,0] - day26.iloc[counter,0])  # Subtract the 26 day EW moving average from the 12 day.\n",
    "        counter += 1\n",
    "    macd_df = pd.DataFrame(macd)\n",
    "    signal_df = macd_df.ewm(span=9).mean() # Create the signal line, which is a 9 day EW moving average\n",
    "    signal = signal_df.values.tolist()  # Add the signal line values to a list.\n",
    "    #  Loop to Compare the expected MACD crosses results to the actual results\n",
    "    Day = 1\n",
    "    while Day < len(macd)-5: # -1 to be able to use the last day for prediction, -5 so we can look at the 5 day post average.\n",
    "        Prev_Day = Day-1\n",
    "        # Avg_Closing_Next_Days = (prices[Day+1] + prices[Day+2] + prices[Day+3] + prices[Day+4] + prices[Day+5])/5 # To use 5 day average as a decision.\n",
    "        Avg_Closing_Next_Days = (prices[Day+1] + prices[Day+2] + prices[Day+3])/3  # To use 3 day average as a decision.\n",
    "        Days_Observed += 1  # Count how many days were observed\n",
    "        if ((signal[Prev_Day] > macd[Prev_Day]) and (signal[Day] <= macd[Day])):  # when the signal line dips below the macd line (Expected increase over the next x days)\n",
    "            Crosses += 1   # register that a cross occurred\n",
    "            if (prices[Day] < Avg_Closing_Next_Days):  # Tests if the price increases over the next x days.\n",
    "                True_Positive += 1\n",
    "            else:\n",
    "                False_Negative += 1\n",
    "\n",
    "        if ((signal[Prev_Day] < macd[Prev_Day]) and (signal[Day] >= macd[Day])): # when the signal line moves above the macd line (Expected dip over the next x days)\n",
    "            Crosses += 1\n",
    "            if (prices[Day] > Avg_Closing_Next_Days):  # Tests if the price decreases over the next x days.\n",
    "                True_Negative += 1\n",
    "            else:\n",
    "                False_Positive += 1\n",
    "        Day += 1\n",
    "    try:\n",
    "        Sensitivity = (True_Positive / (True_Positive + False_Negative)) # Calculate sensitivity\n",
    "    except ZeroDivisionError:  # Catch the divide by zero error\n",
    "        Sensitivity = 0\n",
    "    try:\n",
    "        Specificity = (True_Negative / (True_Negative + False_Positive)) # Calculate specificity\n",
    "    except ZeroDivisionError:\n",
    "        Specificity\n",
    "    try:\n",
    "        Accuracy = (True_Positive + True_Negative) / (True_Negative + True_Positive + False_Positive + False_Negative) # Calculate accuracy\n",
    "    except ZeroDivisionError:\n",
    "        Accuracy = 0\n",
    "    TPR = Sensitivity  # Calculate the true positive rate\n",
    "    FPR = 1 - Specificity  # Calculate the false positive rate\n",
    "    # Create a row to add to the compare_stocks\n",
    "    add_row = {'Company' : Company, 'Days_Observed' : Days_Observed, 'Crosses' : Crosses, 'True_Positive' : True_Positive, 'False_Positive' : False_Positive, \n",
    "    'True_Negative' : True_Negative, 'False_Negative' : False_Negative, 'Sensitivity' : Sensitivity, 'Specificity' : Specificity, 'Accuracy' : Accuracy, 'TPR' : TPR, 'FPR' : FPR} \n",
    "    Compare_Stocks = Compare_Stocks.append(add_row, ignore_index = True) # Add the analysis on the stock to the existing Compare_Stocks dataframe\n",
    "    count += 1\n",
    "Compare_Stocks.to_csv(\"SMA_Analysis/All_Stocks.csv\", index = False)  # Save the compiled data on each stock to a csv - All_Stocks.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-19</th>\n",
       "      <td>577.090027</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>566.450012</td>\n",
       "      <td>574.479980</td>\n",
       "      <td>4807200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-20</th>\n",
       "      <td>564.359985</td>\n",
       "      <td>578.450012</td>\n",
       "      <td>547.179993</td>\n",
       "      <td>571.770020</td>\n",
       "      <td>7966400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-21</th>\n",
       "      <td>573.580017</td>\n",
       "      <td>588.809998</td>\n",
       "      <td>568.219971</td>\n",
       "      <td>575.020020</td>\n",
       "      <td>4952200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-22</th>\n",
       "      <td>588.729980</td>\n",
       "      <td>600.099976</td>\n",
       "      <td>584.109985</td>\n",
       "      <td>596.380005</td>\n",
       "      <td>5120100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-25</th>\n",
       "      <td>597.989990</td>\n",
       "      <td>608.500000</td>\n",
       "      <td>594.559998</td>\n",
       "      <td>596.530029</td>\n",
       "      <td>4396100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Volume  \\\n",
       "Date                                                                  \n",
       "2016-01-19  577.090027  584.000000  566.450012  574.479980  4807200   \n",
       "2016-01-20  564.359985  578.450012  547.179993  571.770020  7966400   \n",
       "2016-01-21  573.580017  588.809998  568.219971  575.020020  4952200   \n",
       "2016-01-22  588.729980  600.099976  584.109985  596.380005  5120100   \n",
       "2016-01-25  597.989990  608.500000  594.559998  596.530029  4396100   \n",
       "\n",
       "            Dividends  Stock Splits  \n",
       "Date                                 \n",
       "2016-01-19          0             0  \n",
       "2016-01-20          0             0  \n",
       "2016-01-21          0             0  \n",
       "2016-01-22          0             0  \n",
       "2016-01-25          0             0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the dataframe that we will be adding the final analysis of each stock to\n",
    "\n",
    "AMZN_path = Path('SMA_Analysis/Stocks/AMZN.csv')\n",
    "AMZN_df=pd.read_csv(AMZN_path,index_col=\"Date\", infer_datetime_format=True, parse_dates=True)\n",
    "#AMZN_df = pd.read_csv(AMZN_path)(columns=[\"Date\",\"Open\", \"Close\", \"Return\", \"12 Day\", \"9 Day\", \"26 Day\", \"Accuracy\"], index = \"Date\")\n",
    "AMZN_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMZN_day12 = AMZN_df.ewm(span=12).mean()  \n",
    "AMZN_day26 = prices_df.ewm(span=26).mean()\n",
    "AMZN_day9 = prices_df.ewm(span=9).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# While loop to cycle through the stock paths\n",
    "count = 0\n",
    "for stock in list_files:\n",
    "    # Dataframe to hold the historical data of the stock we are interested in.\n",
    "    stock_Hist_data = pd.read_csv(stock)\n",
    "    Company = ((os.path.basename(stock)).split(\".csv\")[0])  # Name of the company\n",
    "    # Constants for the stock that we will be updating later\n",
    "    # This list holds the closing prices of a stock\n",
    "    prices = []\n",
    "    c = 0\n",
    "     # Add the closing prices to the prices list and make sure we start at greater than 2 dollars to reduce outlier calculations.\n",
    "    while c < len(Hist_data):\n",
    "        if Hist_data.iloc[c,4] > float(2.00):  # Check that the closing price for this day is greater than $2.00\n",
    "            prices.append(Hist_data.iloc[c,4])\n",
    "        c += 1\n",
    "    prices_df = pd.DataFrame(prices)  # Make a dataframe from the prices list\n",
    "    # Calculate exponentiall weighted moving averages:\n",
    "    day12 = prices_df.ewm(span=12).mean()  #\n",
    "    day26 = prices_df.ewm(span=26).mean()\n",
    "    macd = []  # List to hold the MACD line values\n",
    "    counter=0  # Loop to substantiate the MACD line\n",
    "    while counter < (len(day12)):\n",
    "        macd.append(day12.iloc[counter,0] - day26.iloc[counter,0])  # Subtract the 26 day EW moving average from the 12 day.\n",
    "        counter += 1\n",
    "    macd_df = pd.DataFrame(macd)\n",
    "    signal_df = macd_df.ewm(span=9).mean() # Create the signal line, which is a 9 day EW moving average\n",
    "    signal = signal_df.values.tolist()  # Add the signal line values to a list.\n",
    "    #  Loop to Compare the expected MACD crosses results to the actual results\n",
    "    Day = 1\n",
    "    while Day < len(macd)-5: # -1 to be able to use the last day for prediction, -5 so we can look at the 5 day post average.\n",
    "        Prev_Day = Day-1\n",
    "        # Avg_Closing_Next_Days = (prices[Day+1] + prices[Day+2] + prices[Day+3] + prices[Day+4] + prices[Day+5])/5 # To use 5 day average as a decision.\n",
    "        Avg_Closing_Next_Days = (prices[Day+1] + prices[Day+2] + prices[Day+3])/3  # To use 3 day average as a decision.\n",
    "        Days_Observed += 1  # Count how many days were observed\n",
    "        if ((signal[Prev_Day] > macd[Prev_Day]) and (signal[Day] <= macd[Day])):  # when the signal line dips below the macd line (Expected increase over the next x days)\n",
    "            Crosses += 1   # register that a cross occurred\n",
    "            if (prices[Day] < Avg_Closing_Next_Days):  # Tests if the price increases over the next x days.\n",
    "                True_Positive += 1\n",
    "            else:\n",
    "                False_Negative += 1\n",
    "\n",
    "        if ((signal[Prev_Day] < macd[Prev_Day]) and (signal[Day] >= macd[Day])): # when the signal line moves above the macd line (Expected dip over the next x days)\n",
    "            Crosses += 1\n",
    "            if (prices[Day] > Avg_Closing_Next_Days):  # Tests if the price decreases over the next x days.\n",
    "                True_Negative += 1\n",
    "            else:\n",
    "                False_Positive += 1\n",
    "        Day += 1\n",
    "    try:\n",
    "        Sensitivity = (True_Positive / (True_Positive + False_Negative)) # Calculate sensitivity\n",
    "    except ZeroDivisionError:  # Catch the divide by zero error\n",
    "        Sensitivity = 0\n",
    "    try:\n",
    "        Specificity = (True_Negative / (True_Negative + False_Positive)) # Calculate specificity\n",
    "    except ZeroDivisionError:\n",
    "        Specificity\n",
    "    try:\n",
    "        Accuracy = (True_Positive + True_Negative) / (True_Negative + True_Positive + False_Positive + False_Negative) # Calculate accuracy\n",
    "    except ZeroDivisionError:\n",
    "        Accuracy = 0\n",
    "    TPR = Sensitivity  # Calculate the true positive rate\n",
    "    FPR = 1 - Specificity  # Calculate the false positive rate\n",
    "    # Create a row to add to the compare_stocks\n",
    "    add_row = {'Company' : Company, 'Days_Observed' : Days_Observed, 'Crosses' : Crosses, 'True_Positive' : True_Positive, 'False_Positive' : False_Positive, \n",
    "    'True_Negative' : True_Negative, 'False_Negative' : False_Negative, 'Sensitivity' : Sensitivity, 'Specificity' : Specificity, 'Accuracy' : Accuracy, 'TPR' : TPR, 'FPR' : FPR} \n",
    "    Compare_Stocks = Compare_Stocks.append(add_row, ignore_index = True) # Add the analysis on the stock to the existing Compare_Stocks dataframe\n",
    "    count += 1\n",
    "Compare_Stocks.to_csv(\"SMA_Analysis/All_Stocks.csv\", index = False)  # Save the compiled data on each stock to a csv - All_Stocks.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import hvplot as hv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
